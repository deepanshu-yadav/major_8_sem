{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, merge\n",
    "from keras.layers import Reshape,LeakyReLU,ZeroPadding2D\n",
    "from keras.layers.core import Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Deconvolution2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.objectives import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "#from tqdm import tqdm\n",
    "import scipy.misc as im\n",
    "#K.set_image_dim_ordering('th') \n",
    "IN_CH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob, pickle\n",
    "import os, sys\n",
    "import argparse\n",
    "import cv2\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, merge\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Deconvolution2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import math\n",
    "K.set_image_dim_ordering('tf') \n",
    "\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "SHAPE = 256\n",
    "BATCH = 4\n",
    "IN_CH = 3\n",
    "OUT_CH = 3\n",
    "LAMBDA = 100\n",
    "NF = 64 # number of filter\n",
    "BATCH_SIZE = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_input(img,mode='AtoB'):\n",
    "    \"\"\"\n",
    "    img: an 512x256x3 image\n",
    "    :return: [input, output]\n",
    "    \"\"\"\n",
    "    input, output = img[:,:img_cols,:], img[:,img_cols:,:]\n",
    "\n",
    "    if mode == 'BtoA':\n",
    "        input, output = output, input\n",
    "    if IN_CH == 1:\n",
    "        input = cv2.cvtColor(input, cv2.COLOR_RGB2GRAY)\n",
    "    if OUT_CH == 1:\n",
    "        output = cv2.cvtColor(output, cv2.COLOR_RGB2GRAY)\n",
    "    return [input, output]\n",
    "\n",
    "def get_data(datadir):\n",
    "    #datadir = args.data\n",
    "    # assume each image is 512x256 split to left and right\n",
    "    imgs = glob.glob(os.path.join(datadir, '*.jpg'))\n",
    "    data_X = np.zeros((len(imgs),img_rows,img_cols,3))\n",
    "    data_Y = np.zeros((len(imgs),img_rows,img_cols,3))\n",
    "    i = 0\n",
    "    for file in imgs:\n",
    "        img = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (img_cols*2, img_rows)) \n",
    "        #print('{} {},{}'.format(i,np.shape(img)[0],np.shape(img)[1]))\n",
    "        \n",
    "\n",
    "        X, Y = split_input(img)\n",
    "\n",
    "        data_X[i,:,:,:] = X\n",
    "        data_Y[i,:,:,:] = Y\n",
    "        i = i+1\n",
    "    return data_X, data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x,data_y=get_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(50, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#cv2.imshow(data_x[0])\n",
    "#cv2.waitKey(0)\n",
    "print(type(data_x))\n",
    "print(data_x.shape)\n",
    "img=data_x[0,:,:,:]\n",
    "#cv2.imshow(img,'img')\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    \n",
    "    input_tensor = Input(shape=(img_rows,img_cols,IN_CH)) # type: Input\n",
    "    output_ch = 3\n",
    "    filters=128\n",
    "    x =                       Conv2D(         filters*1, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( input_tensor )       ; e1 = x\n",
    "    x = BatchNormalization()( Conv2D(         filters*2, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( LeakyReLU(0.2)(x) ) ); e2 = x\n",
    "    x = BatchNormalization()( Conv2D(         filters*4, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( LeakyReLU(0.2)(x) ) ); e3 = x\n",
    "    x = BatchNormalization()( Conv2D(         filters*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( LeakyReLU(0.2)(x) ) ); e4 = x\n",
    "    x = BatchNormalization()( Conv2D(         filters*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( LeakyReLU(0.2)(x) ) ); e5 = x\n",
    "    x = BatchNormalization()( Conv2D(         filters*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( LeakyReLU(0.2)(x) ) ); e6 = x\n",
    "    x = BatchNormalization()( Conv2D(         filters*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( LeakyReLU(0.2)(x) ) ); e7 = x\n",
    "    x =                       Conv2D(         filters*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( LeakyReLU(0.2)(x) )  ; e8 = x\n",
    "    # dec\n",
    "    x = BatchNormalization()( Conv2DTranspose(filters*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( Activation(\"relu\")(x) ) ); x = Concatenate()([Dropout(0.5)(x), e7])\n",
    "    x = BatchNormalization()( Conv2DTranspose(filters*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( Activation(\"relu\")(x) ) ); x = Concatenate()([Dropout(0.5)(x), e6])\n",
    "    x = BatchNormalization()( Conv2DTranspose(filters*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( Activation(\"relu\")(x) ) ); x = Concatenate()([Dropout(0.5)(x), e5])\n",
    "    x = BatchNormalization()( Conv2DTranspose(filters*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( Activation(\"relu\")(x) ) ); x = Concatenate()([x, e4])\n",
    "    x = BatchNormalization()( Conv2DTranspose(filters*4, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( Activation(\"relu\")(x) ) ); x = Concatenate()([x, e3])\n",
    "    x = BatchNormalization()( Conv2DTranspose(filters*2, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( Activation(\"relu\")(x) ) ); x = Concatenate()([x, e2])\n",
    "    x = BatchNormalization()( Conv2DTranspose(filters*1, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( Activation(\"relu\")(x) ) ); x = Concatenate()([x, e1])\n",
    "    x =                       Conv2DTranspose(output_ch, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")( Activation(\"relu\")(x) )\n",
    "    \n",
    "    x = Activation(\"tanh\")(x)\n",
    "    \n",
    "    unet = Model(inputs=input_tensor, outputs=x)\n",
    "    \n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 128, 128, 128)     6272      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 64, 64, 256)       524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 1024)      8389632   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 16, 16, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 1024)        16778240  \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 1024)        16778240  \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 1024)        16778240  \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 1, 1, 1024)        16778240  \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 2, 2, 1024)        16778240  \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "concatenate_8 (Concatenate)  (None, 2, 2, 2048)        0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 2, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 4, 4, 1024)        33555456  \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "concatenate_9 (Concatenate)  (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 8, 8, 1024)        33555456  \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "concatenate_10 (Concatenate) (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 16, 16, 1024)      33555456  \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "concatenate_11 (Concatenate) (None, 16, 16, 2048)      0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 16, 2048)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 32, 32, 512)       16777728  \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "concatenate_12 (Concatenate) (None, 32, 32, 1024)      0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 32, 32, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 64, 64, 256)       4194560   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "concatenate_13 (Concatenate) (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 128, 128, 128)     1048704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "concatenate_14 (Concatenate) (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 256, 256, 3)       12291     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 256, 256, 3)       0         \n",
      "=================================================================\n",
      "Total params: 217,648,387.0\n",
      "Trainable params: 217,628,675.0\n",
      "Non-trainable params: 19,712.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gx=generator_model()\n",
    "gx.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_model():    \n",
    "    inputs = Input(shape=(img_cols,img_rows,IN_CH*2))\n",
    "    d = ZeroPadding2D(padding=(1,1))(inputs)\n",
    "    d = Convolution2D(64,4,4,subsample=(2,2))(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ZeroPadding2D(padding=(1,1))(d)\n",
    "    d = Convolution2D(128,4,4,subsample=(2,2))(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ZeroPadding2D(padding=(1,1))(d)\n",
    "    d = Convolution2D(256,4,4,subsample=(2,2))(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ZeroPadding2D(padding=(1,1))(d)\n",
    "    d = Convolution2D(512,4,4,subsample=(1,1))(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ZeroPadding2D(padding=(1,1))(d)\n",
    "    d = Convolution2D(1,4,4,subsample=(1,1),activation='sigmoid')(d)\n",
    "    model = Model(inputs,d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), strides=(2, 2))`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (4, 4), strides=(2, 2))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 256, 256, 6)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 258, 258, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 128, 128, 64)      6208      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 130, 130, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 66, 66, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 34, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 31, 31, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 31, 31, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 33, 33, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 30, 1)         8193      \n",
      "=================================================================\n",
      "Total params: 2,767,809.0\n",
      "Trainable params: 2,767,809.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (4, 4), strides=(2, 2))`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (4, 4), strides=(1, 1))`\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (4, 4), activation=\"sigmoid\", strides=(1, 1))`\n"
     ]
    }
   ],
   "source": [
    "dx=discriminator_model()\n",
    "dx.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    inputs = Input((img_cols, img_rows,IN_CH))\n",
    "    x_generator = generator(inputs)\n",
    "    \n",
    "    merged = merge([inputs, x_generator], mode='concat',concat_axis=-1)\n",
    "    discriminator.trainable = False\n",
    "    x_discriminator = discriminator(merged)\n",
    "    \n",
    "    model = Model(inputs,[x_generator,x_discriminator])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 256, 256, 3)       217648387 \n",
      "_________________________________________________________________\n",
      "merge_1 (Merge)              (None, 256, 256, 6)       0         \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              (None, 30, 30, 1)         2767809   \n",
      "=================================================================\n",
      "Total params: 220,416,196.0\n",
      "Trainable params: 220,396,484.0\n",
      "Non-trainable params: 19,712.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gcd=generator_containing_discriminator(gx,dx)\n",
    "gcd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_on_generator_loss(y_true,y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_pred,y_true), axis=(1,2,3))\n",
    "\n",
    "def generator_l1_loss(y_true,y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true),axis=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pic(generator,target,e):\n",
    "    pic = generator.predict(target)\n",
    "    pic = np.squeeze(pic,axis=0)\n",
    "    target = np.squeeze(target,axis=0)\n",
    "    im.imsave('target_%d.png' % e,target)\n",
    "    im.imsave('pic_%d.png' % e,pic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epochs,batchsize):\n",
    "    \n",
    "    \n",
    "    \n",
    "    pic,target=get_data('train')\n",
    "    pic = pic.astype('float32')\n",
    "    target = target.astype('float32')\n",
    "    pic = (pic - 127.5) / 127.5\n",
    "    target = (target - 127.5) / 127.5\n",
    "    batchCount = pic.shape[0] / batchsize\n",
    "    print('Epochs  ',epochs)\n",
    "    print('Batch_size   ',batchsize)\n",
    "    print('Batches per epoch    ',batchCount)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    generator = generator_model()\n",
    "    \n",
    "    discriminator = discriminator_model()\n",
    "    \n",
    "    gan = generator_containing_discriminator(generator,discriminator)\n",
    "    \n",
    "    generator.compile(loss=generator_l1_loss, optimizer='RMSprop')\n",
    "    \n",
    "    gan.compile(loss=[generator_l1_loss,discriminator_on_generator_loss] , optimizer='RMSprop')\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "    \n",
    "    discriminator.compile(loss=discriminator_on_generator_loss, optimizer='RMSprop')\n",
    "    \n",
    "    \n",
    "    G_loss = []\n",
    "    D_loss = []\n",
    "    for e in range(1,epochs+1):\n",
    "        print('Epoch       {}',e)\n",
    "        for i in range(batchCount):\n",
    "            random_number = np.random.randint(1,pic.shape[0],size=batchsize)\n",
    "            batch_pic = pic[random_number]\n",
    "            batch_target = target[random_number]\n",
    "            batch_target2 = np.tile(batch_target,(2,1,1,1))\n",
    "            y_dis = np.zeros((2*batchsize,30,30,1))\n",
    "            y_dis[:batchsize] = 1.0\n",
    "            generated_pic = generator.predict(batch_target)\n",
    "            #Default is concat first dimention\n",
    "            concat_pic = np.concatenate((batch_pic,generated_pic))\n",
    "            \n",
    "            dis_input = np.concatenate((concat_pic,batch_target2),axis=-1)\n",
    "            \n",
    "            dloss = discriminator.train_on_batch(dis_input,y_dis)\n",
    "            \n",
    "            random_number = np.random.randint(1,pic.shape[0],size=batchsize)\n",
    "            \n",
    "            train_target = target[random_number]\n",
    "            \n",
    "            batch_pic = pic[random_number]\n",
    "            \n",
    "            y_gener = np.ones((batchsize,30,30,1))\n",
    "            \n",
    "            discriminator.trainable = False\n",
    "            \n",
    "            gloss = gan.train_on_batch(train_target,[batch_pic,y_gener])\n",
    "            \n",
    "            discriminator.trainable = True\n",
    "            \n",
    "        G_loss.append(gloss)\n",
    "        D_loss.append(dloss)\n",
    "        if e % 50 == 0 or e == 1:\n",
    "            generate_pic(generator,target[0:1],e)\n",
    "            \n",
    "            generator.save('Model_para/pix2pix_g_epoch_%d.h5' % e)\n",
    "            \n",
    "            discriminator.save('Model_para/pix2pix_d_epoch_%d.h5' % e)\n",
    "            \n",
    "            gan.save('Model_para/pix2pix_gan_epoch_%d.h5' % e)\n",
    "            \n",
    "    D_loss = np.array(D_loss)\n",
    "    G_loss = np.array(G_loss)\n",
    "    np.save('Model_para/dloss.npy',D_loss)\n",
    "    np.save('Model_para/gloss.npy',G_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
